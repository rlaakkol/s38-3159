\documentclass[a4paper]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{graphicx}
\usepackage[ELEC]{aaltologo}
\usepackage{verbatim}
\usepackage[bf,small]{caption}
\usepackage[toc,page]{appendix}

\usepackage{pdfpages}

\begin{document}
% Titlepage
\input{documentation-cover.tex}

\tableofcontents
\newpage

\section{Implementation structure}

We implemented the server and client portions of our publish-subscribe specification using the \textbf{Python 3.2} programming language.

The implementation provides \texttt{ps-server} and \texttt{ps-client} scripts based on a shared \texttt{pubsub} library package.
The server receives sensor updates and client messages, maintains state for all active sensors and client sessions, handles publishing and aggregation of sensor updates to subscribed clients, and responds to stateless client queries.
The client supports sending stateless queries (listing available sensors), and establishing a subscription session for a given set of sensors (defaulting to all sensors).

The executable scripts are responsible for command-line argument handling and setting up sensor logging, whereas the actual high-level protocol semantics (\textbf{SUBSCRIBE}, \textbf{PUBLISH}, \textbf{TEARDOWN}) and related state are implemented in the \texttt{pubsub.client} and \texttt{pubsub.server} modules.
Both modules use the same \texttt{pubsub.protocol} module which implements the protocol syntax and generic non-message-type-specific protocol semantics, including request acknowledgements/responses and timeouts/retransmissions.
The UDP transport (including the multiplexing reactor with timeout scheduling) is implemented in \texttt{pubsub.udp}.
The JSONish format used for building/parsing protocol message payloads, as well as parsing sensor updates, is implemented in \texttt{pubsub.jsonish}.

\section{Implementation issues}

We feel that Python was an excellent choice for the implementation, and got off to a strong start, having a basic functional prototype (without any header syntax or protocol semantics) as a starting point before even finishing the revision 1 specification.
Implementing the basic UDP mechanics and protocol syntax (encoding) was straightforward, and let us concentrate on the actual protocol semantics.

The \texttt{pubsub.server} and \texttt{pubsub.protocol} modules do implement backwards-compatibility based on the magic contained in the packets sent by the client, supporting both revision 2 clients (magic \texttt{0x43}) as well as revision 1 clients (magic \texttt{0x42}) simultaneously.
However, while the \texttt{pusub.client} partially implements support for revision 1 (magic \texttt{0x42}) messages, this support is incomplete and would require some form of explicit flag (\texttt{\--\--revision-1}) or fallback mechanism to communicate with an older server, as the origional server implemention will silently discard any magic \texttt{0x43} messages.

\section{Implementation vs specification differences}

The protocol encoding is fully implemented per both specification revisions, including both revision 1/2 binary header formats, the revision 2 extended \textbf{SUBSCRIBE} syntax for aggregation expressions, and both revision 1/2 \texttt{PUBLISH} formats.

Message sequence numbers are implemented by the the low-level \texttt{pubsub.protocol} module for all message types, including both allocation of sequence numbers for sent requests as well as automatic acknowledgements/discards of received (duplicate or out-of-order) sequence numbers.
The same logic provides for timeouts/retransmissions of unacknowledged requests (including stateless queries as a special case).
However, sequence number wraparound is not implemented, and the session is always established with a starting \texttt{seq=1}.

\subsection{\textbf{SUBSCRIBE}}
The \textbf{SUBSCRIBE} implementation follows the specification, implementing all \textbf{subscribe-*} message variants.
The five-way \textbf{SUBSCRIBE} handshake for mitigating DoS reflection attacks in the session setup phase is not implemented.

The \textbf{subscribe-query}/\textbf{subscribe-queryresponse} exchange is implemented by the server in a stateless fashion, with the client handling timeout/retransmission state (assuming a single in-flight query with no other messages being exchanged).

The three-way \textbf{subscribe-request}/\textbf{subscribe-response}/\textbf{subscribe-ack} exchange is used for session establishment between the client and server.
The client handles retransmission of lost \textbf{subscribe-request} messages per the spec.
The server handling of \textbf{subscribe-response} retransmissions differs slightly in that while the initial \textbf{subscribe-response} is a combined ack/response, a lost \textbf{subscribe-response} will result in a ack-only message for the client-retransmitted \textbf{subscribe-request} and a separate retransmitted \textbf{subscribe-response} message without any ack-seq.
This variant can however be considered equivalent per the protocol semantics, if somewhat inefficient.

While the \textbf{pubsub.client} and \textbf{pubsub.server} implementation would theoretically support \textbf{subscribe-request} updates to change the subscription set for a running session, the \texttt{ps-client} interface does not provide any runtime mechanism for changing the subscription set, nor has this behaviour been tested.

The \textbf{subscribe-update}/\textbf{subscribe-ack} exchange is implemented for the server-initiated addition of new sensors to a sesion implicitly subscribed to all sensors, and the client will log the addition/removal of sensors to its subscription set.
The server does not, however, implement updates for removing sensors that have timed out.

\subsection{\textbf{PUBLISH}}
The basic \textbf{PUBLISH} mechanism is implemented according to the specification.
The keep-alive \textbf{publish (w/ NoAck unset)} messages from the server should have contained the values from the subscribed device-type sensors, but are transmitted with either an empty payload, or in the form of a normal \textbf{publish} message.

The client does not transmit any count of received \textbf{PUBLISH} messages in the \textbf{publish-ack} \textit{seq} field.
The specification should be changed to use a separate payload field instead.
The server does not implement any congestion control for sent \textbf{PUBLISH} messages either, beyond the keepalive timeout mechanism for terminating the client session.

\subsection{\textbf{TEARDOWN}}
The client and server implement \textbf{TEARDOWN} support.
The client will send a \textbf{teardown} message and wait for a \textbf{teardown-ack} when terminating with \texttt{SIGINT} (Ctrl-c), retransmitting the \textbf{teardown} as required.

\section{Testing scenarios and metrics}


\subsection{Testing packet loss vs Freshness metric}
The effect of packet loss on the protocol and the implementation was tested by 
making the section of the code that handles the sending of UDP packets (utilized
by both the server and the client) drop packets with an adjustable rate.
Different loss rates were tested by running the server with a single temperature
sensor and one client for 1-2 minutes each. The results are visible in Figure 
\ref{fig:lossdata}.

\begin{figure}[h!]
\center{
    \includegraphics[width=\textwidth]{plots/plotdata.pdf}
}
\caption{Average and maximum values for time between consecutive updates arriving at the client with one temperature sensor.} \label{fig:lossdata}
\end{figure}

The image shows the average and maximum time between consecutive sensor updates.
As the temperature sensor sends updates at a constant 1 update per second rate,
the maximum time data points nicely visualize the maximum amount of consecutive
updates (with payload) lost.

As there are no retransmissions for publish messages in the protocol, the amount
of lost updates is the same as the loss ratio. With the smallest possible values
for timeouts according to the specification, a timeout disconnect first happened
at a packet loss rate of 50\%. Even at 40\% the maximum amount of consecutive
packets lost was 6.

\subsection{Testing scenario Z sensor set}
We tested the ``scenario Z'' by creating a shell script
for starting the sensors and then running one server and one client. If all
sensors where running, the client was unable receive any messages from the
server causing the server to time out. When one camera and audio sensor along
with the other sensor types where running, the sensor received the \emph{publish}
messages correctly. Thus we can conclude that running too many (at least five
camera and seven audio sensors) simultaneous camera and audio sensors consume
all of the server's processing time.

\section{Lessons learnt: what we would do differently}
We would likely have done most things the same way if we had to the assignment
again from scratch but naturally some things would have been changed. The most
common thing was that certain values or semantics in the specification were
missing or unclear. One example is the retransmission timeout for \emph{teardown}
messages sent by the client. Also the semantics for the aggregation methods
were unspecified and some aggregation methods for the camera and audio sensors
could have been added. 

% Design:
% - Specify default values for all timeouts, particularly teardown
%   - Can the timeouts be changed?
% - Specify semantics for aggregation expressions
% - Add aggregation expressions also for other sensors, e.g. camera and asd

\section{Learning diary}
The learning diary consists mostly of matters relating to the design and the
assignment 1 implementation of the protocol. The diary is shown below.

The detailed implementation progress can be be seen from the commit log of our
Git repository. It is included in Appendix \ref{lst:commit_log}.

\input{AssignmentDiary.tex}

\clearpage
\begin{appendices}
  \section{Git commit log}\label{lst:commit_log}
  \verbatiminput{commit_log.txt}
\end{appendices}

\end{document}
